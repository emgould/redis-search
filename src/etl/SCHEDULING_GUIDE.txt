# ETL Scheduling Implementation Guide

## Overview

This document outlines the implementation plan for scheduling the nightly TMDB Changes ETL on Google Cloud Run. The core ETL logic is complete and tested; this phase focuses on deployment, scheduling, and production hardening.

---

## Current State (Completed)

### Core ETL Components
| Component | Location | Purpose |
|-----------|----------|---------|
| tmdb_changes_etl.py | src/etl/ | Fetches TMDB changes, enriches, filters, upserts to Redis |
| etl_runner.py | src/etl/ | Orchestrates jobs from YAML config |
| etl_metadata.py | src/etl/ | Persists run metadata to GCS |
| etl_jobs.yaml | config/ | Job definitions (tv, movie, person) |
| ETL API endpoints | web/app.py | HTTP triggers and status endpoints |
| ETL Dashboard | web/templates/etl.html | Manual trigger UI with progress |

### Existing HTTP Endpoints

POST /api/etl/trigger          - Trigger full ETL run
GET  /api/etl/status           - Get current run status
POST /api/etl/job/trigger      - Trigger single job (tv/movie/person)
GET  /api/etl/job/status/{id}  - Get job status with progress
GET  /api/etl/config           - View YAML configuration
GET  /api/etl/jobs             - List configured jobs
GET  /api/etl/runs             - List recent runs from GCS
GET  /api/etl/job/state        - Get persistent job states


### How the ETL Works
1. Trigger: HTTP POST to /api/etl/trigger (or scheduled)
2. Load Config: Reads config/etl_jobs.yaml
3. Determine Dates: For each job, gets start_date from last successful run in GCS
4. Fetch Changes: Calls TMDB /tv/changes, /movie/changes, /person/changes
5. Enrich: Gets full details for each changed ID (batched, rate-limited)
6. Filter: Applies quality rules (popularity, votes, poster, recency/streaming)
7. Upsert: JSON.SET to Redis (creates or updates)
8. Persist Metadata: Saves run results to GCS for tracking

---

## Implementation Tasks

### Phase 1: Production Hardening

#### 1.1 Add Health Check Endpoint
Cloud Run requires a health endpoint for container management.

    # web/app.py
    
    @app.get("/health")
    async def health_check():
        return {
            "status": "healthy",
            "service": "redis-search-etl",
            "timestamp": datetime.now().isoformat(),
        }
    
    @app.get("/ready")
    async def readiness_check():
        checks = {"redis": False, "gcs": False}
        
        try:
            redis = await get_redis()
            await redis.ping()
            checks["redis"] = True
        except Exception:
            pass
        
        try:
            from google.cloud import storage
            client = storage.Client()
            checks["gcs"] = True
        except Exception:
            pass
        
        all_ready = all(checks.values())
        return JSONResponse(
            status_code=200 if all_ready else 503,
            content={"ready": all_ready, "checks": checks}
        )

#### 1.2 Add Authentication for Scheduled Triggers
Cloud Scheduler sends headers we can verify.

    # web/app.py
    
    from fastapi import Header, HTTPException
    import os
    
    def verify_scheduler_auth(
        x_cloudscheduler_jobname: str | None = Header(None, alias="X-CloudScheduler-JobName"),
        x_api_key: str | None = Header(None, alias="X-API-Key"),
    ) -> bool:
        if x_cloudscheduler_jobname:
            return True
        
        expected_key = os.getenv("ETL_API_KEY")
        if expected_key and x_api_key == expected_key:
            return True
        
        if os.getenv("ENVIRONMENT", "development") == "development":
            return True
        
        return False

#### 1.3 Add Timeout Configuration
The ETL can run 30-60 minutes for large change sets.

    # src/etl/tmdb_changes_etl.py
    
    ETL_TIMEOUT_SECONDS = int(os.getenv("ETL_TIMEOUT_SECONDS", "3600"))
    
    async def run_changes_etl(...):
        try:
            async with asyncio.timeout(ETL_TIMEOUT_SECONDS):
                # ... existing ETL logic
        except asyncio.TimeoutError:
            stats.errors.append(f"ETL timed out after {ETL_TIMEOUT_SECONDS}s")
            stats.completed_at = datetime.now()
            return stats

#### 1.4 Add Idempotency Check
Prevent duplicate runs on the same day.

    # src/etl/etl_runner.py
    
    async def run_all(self, force_rerun: bool = False, ...):
        today = date.today().isoformat()
        latest_run = self.metadata_store.get_latest_run()
        
        if latest_run and latest_run.run_date == today and latest_run.status == "completed":
            if not force_rerun:
                logger.info(f"ETL already completed today, skipping")
                return latest_run

---

### Phase 2: Cloud Run Deployment

#### 2.1 Dockerfile Updates

    FROM python:3.11-slim
    WORKDIR /app
    COPY requirements.txt .
    RUN pip install --no-cache-dir -r requirements.txt
    COPY . .
    ENV PYTHONPATH=/app/src:/app
    ENV PORT=8080
    CMD ["uvicorn", "web.app:app", "--host", "0.0.0.0", "--port", "8080"]

#### 2.2 Deploy Commands

    # Build and push image
    gcloud builds submit --tag gcr.io/PROJECT_ID/redis-search-etl
    
    # Deploy service
    gcloud run deploy redis-search-etl \
        --image gcr.io/PROJECT_ID/redis-search-etl \
        --platform managed \
        --region us-central1 \
        --timeout 3600 \
        --memory 2Gi \
        --cpu 2 \
        --concurrency 1 \
        --no-allow-unauthenticated \
        --service-account etl-runner@PROJECT_ID.iam.gserviceaccount.com

---

### Phase 3: Cloud Scheduler Setup

#### 3.1 Create Scheduler Job

    gcloud scheduler jobs create http redis-search-nightly-etl \
        --location us-central1 \
        --schedule "0 3 * * *" \
        --uri "https://redis-search-etl-HASH-uc.a.run.app/api/etl/trigger" \
        --http-method POST \
        --oidc-service-account-email etl-scheduler@PROJECT_ID.iam.gserviceaccount.com \
        --oidc-token-audience "https://redis-search-etl-HASH-uc.a.run.app" \
        --headers "Content-Type=application/json" \
        --message-body '{"source": "scheduler"}'

#### 3.2 IAM Permissions

    # Allow scheduler to invoke Cloud Run
    gcloud run services add-iam-policy-binding redis-search-etl \
        --region us-central1 \
        --member "serviceAccount:etl-scheduler@PROJECT_ID.iam.gserviceaccount.com" \
        --role "roles/run.invoker"
    
    # Allow ETL service account to access GCS
    gcloud projects add-iam-policy-binding PROJECT_ID \
        --member "serviceAccount:etl-runner@PROJECT_ID.iam.gserviceaccount.com" \
        --role "roles/storage.objectAdmin"

---

## Environment Variables

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| REDIS_HOST | Yes | - | Redis server hostname |
| REDIS_PORT | Yes | 6380 | Redis server port |
| REDIS_PASSWORD | Yes | - | Redis password |
| GCS_BUCKET | Yes | - | GCS bucket for metadata |
| GCS_ETL_PREFIX | No | redis-search/etl | GCS path prefix |
| TMDB_READ_TOKEN | Yes | - | TMDB API bearer token |
| ETL_CONFIG_PATH | No | config/etl_jobs.yaml | Path to job config |
| ETL_TIMEOUT_SECONDS | No | 3600 | ETL timeout in seconds |
| ETL_API_KEY | No | - | API key for manual triggers |
| ENVIRONMENT | No | development | development or production |

---

## Testing Checklist

### Local Testing
- [ ] Run full ETL against local Redis: POST /api/etl/trigger
- [ ] Verify all 3 jobs complete (tv, movie, person)
- [ ] Verify metadata saved to GCS (or logged if no bucket)
- [ ] Verify documents upserted to Redis
- [ ] Test with date overrides
- [ ] Test individual job triggers

### Staging Testing
- [ ] Deploy to Cloud Run staging
- [ ] Manually trigger via /api/etl/trigger
- [ ] Verify Cloud Scheduler can invoke endpoint
- [ ] Verify secrets are accessible
- [ ] Monitor logs during execution
- [ ] Verify GCS metadata written

### Production Deployment
- [ ] Deploy to Cloud Run production
- [ ] Create Cloud Scheduler job (paused)
- [ ] Manually trigger one successful run
- [ ] Verify Redis data looks correct
- [ ] Enable Cloud Scheduler job
- [ ] Monitor first automated run
- [ ] Set up alerting

---

## Rollback Plan

If ETL causes issues:

1. Disable Scheduler:
   gcloud scheduler jobs pause redis-search-nightly-etl --location us-central1

2. Revert Cloud Run:
   gcloud run services update-traffic redis-search-etl \
       --to-revisions PREVIOUS_REVISION=100 \
       --region us-central1

---

## Quick Reference

### Manual ETL Trigger (curl)

    # Local
    curl -X POST http://localhost:8000/api/etl/trigger
    
    # With date override
    curl -X POST http://localhost:8000/api/etl/trigger \
      -H "Content-Type: application/json" \
      -d '{"start_date": "2025-12-01", "end_date": "2025-12-08"}'
    
    # Single job
    curl -X POST "http://localhost:8000/api/etl/job/trigger?media_type=tv"

### Check Status

    curl http://localhost:8000/api/etl/status
    curl http://localhost:8000/api/etl/job/status/{task_id}
    curl http://localhost:8000/api/etl/runs

---

## Architecture

Cloud Scheduler (3 AM daily cron)
         |
         | HTTP POST /api/etl/trigger
         v
Cloud Run Service (redis-search-etl)
    web/app.py - FastAPI endpoints
         |
    src/etl/etl_runner.py - Loads config, runs jobs
         |
    src/etl/tmdb_changes_etl.py - Fetch/Enrich/Filter/Upsert
         |
    +----+----+
    |         |
    v         v
TMDB API   Redis Search
           (upserts)
    |
    v
GCS (metadata)

---

Last Updated: December 2024

