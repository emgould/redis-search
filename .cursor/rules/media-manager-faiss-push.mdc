# Media Manager FAISS Push — Backfill, ETL & Client

## Overview

Redis Search pushes media documents to the Media Manager FAISS index via HTTP.
The adapter (`src/adapters/media_manager_client.py`) wraps the `/insert-docs`
endpoints. Two paths feed documents into Media Manager:

1. **Backfill** (`scripts/backfill_media_manager_faiss.py`): Seeds the FAISS index
   from existing `idx:media` documents using Redis SCAN.
2. **Nightly ETL** (`src/etl/tmdb_nightly_etl.py` via `ETLRunner`): Pushes
   newly changed/created movie and TV documents to Media Manager as part of the
   daily ETL pipeline, immediately after they are written to Redis.

Both paths use the shared `passes_media_manager_filter` from
`src/etl/media_manager_filter.py` as the intake gate.

## Environment Variables

| Variable | Purpose | Example |
|---|---|---|
| `MEDIA_MANAGER_API_URL` | Base URL of Media Manager service | `https://media-manager-web-development-wabm4u2pza-uc.a.run.app` |
| `MEDIA_MANAGER_INTERNAL_TOKEN` | Auth token sent as `X-Internal-Token` header | `media-circle-5450` |

Both are defined in `config/local.env` and `config/etl.dev.env`.

If `MEDIA_MANAGER_API_URL` is not set, the nightly ETL skips Media Manager
push entirely (Redis writes still proceed normally).

## MediaManagerClient

Async `httpx` client at `src/adapters/media_manager_client.py`.

- Default timeout: **3600 seconds** (1-hour fail-safe matching Cloud Run limits).
- `health_check()` — `GET /health`, raises `RuntimeError` if unhealthy or unreachable.
- `insert_docs(documents, dry_run)` — `POST /insert-docs` with batch of up to 100 docs.
- `get_status()` — `GET /insert-docs/status` for queue depth and session stats.
- `flush()` — `POST /insert-docs/flush`, blocks until queue drains.
- `poll_until_drained(poll_interval, max_wait)` — Polls status until `queue_depth == 0`.
- `close()` — Closes the underlying httpx client.

## Nightly ETL Integration

### How It Works

1. `ETLRunner.run_all()` creates a `MediaManagerClient` and runs a health check
   before any jobs execute. If the health check fails, MM push is disabled for
   the entire run (Redis ETL proceeds unaffected).
2. For each **movie** or **tv** TMDB job, the MM client is passed through
   `run_nightly_etl()` → `load_from_staging()`.
3. Inside `load_from_staging`, after each batch is written to Redis, each document
   is evaluated by `passes_media_manager_filter`. Qualifying docs are buffered and
   submitted to `/insert-docs` in batches of 100.
4. **Person**, **podcast**, and **bestseller** jobs do not push to Media Manager.
5. After all jobs complete, `ETLRunner` polls until the queue drains, then calls
   `/insert-docs/flush` once to finalize the session. Flush errors are logged but
   do not fail the ETL run.

### Stats

`ChangesETLStats` tracks four MM-specific counters:
- `mm_docs_sent` — documents submitted to `/insert-docs`
- `mm_docs_queued` — documents accepted into the queue by Media Manager
- `mm_docs_filtered` — documents rejected by `passes_media_manager_filter`
- `mm_errors` — insert errors (network or server-side)

These propagate into `JobRunResult.mm_docs_sent` and
`ETLRunMetadata.total_mm_docs_sent` for end-of-run reporting.

### Error Handling

All Media Manager operations are **non-fatal** to the core ETL:
- Health check failure at startup → MM push disabled, ETL continues.
- Individual `insert_docs` failure → logged, error count incremented, next batch proceeds.
- Flush failure → logged, does not affect ETL status.

## Backfill Script Usage

```bash
# Dry-run: scan Redis + validate docs + health-check endpoint, no submissions
python scripts/backfill_media_manager_faiss.py --dry-run

# Dry-run with limit (scan only 20 docs)
python scripts/backfill_media_manager_faiss.py --dry-run --limit 20

# Limited live test (submit 20 docs, skip flush)
python scripts/backfill_media_manager_faiss.py --limit 20 --no-flush

# Full backfill with poll-before-flush finalization
python scripts/backfill_media_manager_faiss.py
```

### CLI Flags

| Flag | Default | Description |
|---|---|---|
| `--scan-count` | 500 | Keys per SCAN iteration |
| `--limit` | None | Max documents to submit |
| `--batch-size` | 100 | Docs per POST (max 100) |
| `--dry-run` | off | Scan + validate only, no endpoint submissions |
| `--no-flush` | off | Skip `/insert-docs/flush` after all batches |

### Finalization Strategy

Both the backfill script and the ETL runner use **poll-before-flush**: after
submitting all batches, poll `/insert-docs/status` every 5 seconds until the
queue is empty, then call flush. The 1-hour client timeout serves as a fail-safe.
